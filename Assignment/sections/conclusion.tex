From the completion of this assignment, it is clear that the task of training a
neural network on a small database is challenging. Attaining high accuracy can
be very difficult. It is also challenging to achieve high accuracy when manually
tuning hyperparameters. A better understanding of automated tools for
hyperperameter tuning, or a better understanding of hyperparameter tuning in
general would undoubtedly have yielded better performance from the model.

Transfer learning proves extremely useful in training a model when given a small
dataset. The ability to take a pretrained model and train a different final
classifier is an excellent way of achieving high accuracy with predictions, as
shown in Question 2 Part a.

The differences in CO2 emissions from training a model with no dropout, data
augmentation, and batch normalisation, to training a model with these techniques
implemented is quite large. However, there is an even more extreme difference to
be seen in using fine-tuning based transfer learning, which had the lowest
emission equivalent value by far. This does not, however, take into account the
training of the model used, but the ability to retrain for different datasets
will cut down on emissions which would otherwise be caused by running hardware
to train newly developed models for every classification task.
